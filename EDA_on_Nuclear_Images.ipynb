{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDA on Nuclear Images.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "K50JwB0K0RdD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Set-up"
      ]
    },
    {
      "metadata": {
        "id": "UtX3VXYp0ILi",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Link to Google Drive\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "# Create directory called 'drive'\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ENi48qvVjr2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/drive/CSML Project"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XbsyPWrx0Z3_",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title install additional packages\n",
        "!pip install openpyxl\n",
        "!pip install imageio\n",
        "!pip install shapely\n",
        "!pip install contrastive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MfVey7yW1DS6",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title import packages\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "#from keras.applications import vgg16 #, inception_v3, resnet50, mobilenet\n",
        "import time\n",
        "import openpyxl\n",
        "import seaborn as sns\n",
        "#import zipfile\n",
        "import imageio\n",
        "from skimage.transform import resize\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, \\\n",
        "precision_recall_fscore_support, classification_report\n",
        "\n",
        "from keras.backend import expand_dims\n",
        "from keras.layers import Conv2D, Dense, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D, Flatten\n",
        "from keras.layers import Input, Dense, concatenate\n",
        "from keras.layers import BatchNormalization, Activation\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import zipfile\n",
        "\n",
        "import statsmodels.api as sm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lNnWwzG8XPYe",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title import sample labels\n",
        "\n",
        "wb = openpyxl.load_workbook('file_list.xlsx', read_only=True, data_only=True)\n",
        "ws = wb['file_list']\n",
        "labels = {}\n",
        "for i in range(1, ws.max_row+1):\n",
        "    fname = ws['A'+str(i+1)].value\n",
        "    if fname is None:\n",
        "        break\n",
        "    labels[fname] = {'Grade': ws['F'+str(i+1)].value, 'Exclude': ws['G'+str(i+1)].value}\n",
        "wb.close()\n",
        "\n",
        "labels = pd.DataFrame(labels).transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pBWCUlCUd0Da",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# XML data formatting"
      ]
    },
    {
      "metadata": {
        "id": "yxN3MQ5Bd2xu",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title import additional packages\n",
        "import matplotlib.image as img\n",
        "import xml.etree.ElementTree as ET"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QyynfctFeJX6",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title define XML2DataFrame object\n",
        "class XML2DataFrame:\n",
        "\n",
        "    def __init__(self, xml_fname):\n",
        "        with open(xml_fname, 'r') as myfile:\n",
        "            xml_data=myfile.read()\n",
        "        self.root = ET.XML(xml_data)\n",
        "\n",
        "    def parse_root(self, root):\n",
        "        return [self.parse_element(child) for child in iter(root) if child.tag[-7:] == 'Results']\n",
        "\n",
        "    def parse_element(self, element, parsed=None):\n",
        "        if parsed is None:\n",
        "            parsed = dict()\n",
        "        for key in element.keys():\n",
        "            parsed[key] = element.attrib.get(key)\n",
        "        if element.text:\n",
        "            parsed[element.tag] = element.text\n",
        "        for child in list(element):\n",
        "            self.parse_element(child, parsed)\n",
        "        return parsed\n",
        "\n",
        "    def process_data(self):\n",
        "        structure_data = self.parse_root(self.root)\n",
        "        return pd.DataFrame(structure_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ENUBYXbieSrr",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title format xml files one by one\n",
        "xml_df_list = []\n",
        "i = 0\n",
        "n = 1\n",
        "start_time = time.time()\n",
        "for file in os.listdir('Nisch Pleomorphic Sarcomas'):\n",
        "    if file.endswith(\".param\"):\n",
        "        xml2df = XML2DataFrame('Nisch Pleomorphic Sarcomas\\\\'+file)\n",
        "        xml_df = xml2df.process_data()\n",
        "        xml_df = xml_df.assign(fname=file[:-6])\n",
        "        print(n, \":\", file[:-6], \":\", xml_df.shape, \":\", i, \"-\", i+xml_df.shape[0])\n",
        "        i += xml_df.shape[0]\n",
        "        n += 1\n",
        "        col_names = [k.replace('{http://tempuri.org/CellParametersDS.xsd}','') for k in xml_df.columns]\n",
        "        xml_df.columns = col_names\n",
        "        xml_df_list.append(xml_df)\n",
        "xml_all = pd.concat(xml_df_list,sort=False).reset_index(drop=True)\n",
        "print(time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time)))\n",
        "\n",
        "# save\n",
        "\n",
        "#xml_all.to_csv('xml_all.csv', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ItbbkXE2fZep",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title delete redundant features\n",
        "xml_all = pd.read_csv('xml_all.csv', index_col='GUID')\n",
        "\n",
        "del xml_all['Unnamed: 0']\n",
        "del xml_all['Results']\n",
        "del xml_all['STACKGUID']\n",
        "\n",
        "for col in xml_all.columns:\n",
        "    if len(xml_all[col].unique())==1:\n",
        "        print(col)\n",
        "        del xml_all[col]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WyL9n2Mm2p43",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Normalization"
      ]
    },
    {
      "metadata": {
        "id": "7cIOPAoj2pNU",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title read in XML data\n",
        "xml_all = pd.read_csv('xml_all.csv', index_col='GUID')\n",
        "\n",
        "# delete entries from rubbish galleries\n",
        "xml_all.drop(index=xml_all[xml_all['GALLERY']>3].index, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l5eF04EjW4-R",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title define function to find the leftmost peak over a threshold\n",
        "def find_leftmost_peak(hist, bin_width, threshold): \n",
        "    \n",
        "    hist = hist[:(1000//bin_width)]\n",
        "    if max(hist)<(threshold/bin_width):\n",
        "        threshold /= 2\n",
        "    hist_modes = (hist >= np.insert(hist[1:], -1, 1)) & (hist >= np.insert(hist[:-1], 0, 1)) & (hist >= (threshold/bin_width))\n",
        "    index = list(np.arange(len(hist))[hist_modes])\n",
        "    \n",
        "    i = 0\n",
        "    while i<len(index)-1 and len(index)>1:\n",
        "        #if index[i+1]-index[i]<=int(index[i+1]*2/5):\n",
        "        if np.sum(hist[index[i]:index[i+1]]<threshold/bin_width)==0: \n",
        "            if hist[index[i]]>=hist[index[i+1]]:\n",
        "                index.pop(i+1)\n",
        "            else:\n",
        "                index.pop(i)\n",
        "        else:\n",
        "            i += 1\n",
        "    #print(index)\n",
        "    return index[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nEvTYhHgXEdF",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title identify the diploid peak (leftmost peak above the 10%)\n",
        "\n",
        "bin_width = 25\n",
        "bins = np.arange(0, 4000, bin_width)\n",
        "\n",
        "IOD = xml_all[['fname', 'GALLERY', 'IOD']].copy()\n",
        "\n",
        "for fname in IOD['fname'].unique():\n",
        "    plt.clf()\n",
        "    plt.subplots(figsize=(9, 5))\n",
        "    # plot all cells\n",
        "    hist, _ = np.histogram(np.clip(IOD.loc[IOD['fname']==fname]['IOD'], a_min=bins[0], a_max=bins[-1]), \n",
        "                           bins=bins, density=True)\n",
        "\n",
        "    plt.bar(bins[1:], hist*bin_width, width=bin_width, alpha=0.7)\n",
        "\n",
        "    # plot normal cells\n",
        "    if IOD.loc[(IOD['fname']==fname) & (IOD['GALLERY']==2)].shape[0]>30:\n",
        "        hist_normal, _ = np.histogram(np.clip(IOD.loc[(IOD['fname']==fname) & (IOD['GALLERY']==2)]['IOD'], a_min=bins[0], a_max=bins[-1]), \n",
        "                                      bins=bins, density=True)\n",
        "        plt.bar(bins[1:], hist_normal*bin_width, width=bin_width, alpha=0.7)\n",
        "\n",
        "    # identify diploid peak\n",
        "    normal_mode = hist_normal.argmax()\n",
        "    peak_pos = find_leftmost_peak(hist, bin_width, 0.1)\n",
        "    plt.bar(bins[1:], np.asarray([hist[i] if i==peak_pos else 0 for i in range(len(hist))])*bin_width, \n",
        "            width=bin_width, color='red')\n",
        "\n",
        "    plt.legend(['All cells', 'Normal cells (PWS)', 'identified dipoid peak'])\n",
        "    plt.title(fname + ' Ave normal IOD: ' + str(np.average(IOD.loc[(IOD['fname']==fname) & (IOD['GALLERY']==2)]['IOD'])))\n",
        "\n",
        "    print(IOD.loc[(IOD['fname']==fname) & (IOD['GALLERY']==2)].shape[0], ' normal cells')\n",
        "    \n",
        "    if labels.loc[fname, 'Exclude']=='Yes':\n",
        "        pic_name = '(' + labels.loc[fname, 'Grade'] + ') ' + fname + ' (Excluded)'\n",
        "    else:\n",
        "        pic_name = '(' + labels.loc[fname, 'Grade'] + ') ' + fname\n",
        "    plt.savefig('Visuals\\\\IOD Histogram\\\\Identify diploid\\\\' + pic_name + '.png')\n",
        "    plt.show()\n",
        "    #break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VXJz9P9WXct1",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title collect the location of the identified diploid peak\n",
        "\n",
        "bin_width = 25\n",
        "bins = np.arange(0, 4000, bin_width)\n",
        "\n",
        "IOD = xml_all[['fname', 'GALLERY', 'IOD']].copy()\n",
        "\n",
        "peak_positions = {}\n",
        "\n",
        "for fname in IOD['fname'].unique():\n",
        "    # plot all cells\n",
        "    hist, _ = np.histogram(np.clip(IOD.loc[IOD['fname']==fname]['IOD'], a_min=bins[0], a_max=bins[-1]), \n",
        "                           bins=bins, density=True)\n",
        "    \n",
        "    peak_pos = find_leftmost_peak(hist, bin_width, 0.025)\n",
        "    peak_positions[fname] = {}\n",
        "    peak_positions[fname]['peak_l'] = bins[peak_pos]\n",
        "    peak_positions[fname]['peak_r'] = bins[1+peak_pos]\n",
        "\n",
        "peak_dict = pd.DataFrame.from_dict(data=peak_positions, orient='index')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BWsNFBoNYXyD",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title get the AREA of the cells corresponding to the peak\n",
        "\n",
        "area_dict = pd.merge(peak_dict, xml_all[['fname', 'IOD', 'AREA']], left_index=True, right_on='fname')\n",
        "area_dict['peak_indicator'] = (area_dict['IOD']>area_dict['peak_l']) & (area_dict['IOD']<area_dict['peak_r'])\n",
        "area_dict.drop(index=area_dict.loc[area_dict['peak_indicator']==False].index, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zhAoJ963Yz5P",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title find the sample normalizers for IOD and AREA and save\n",
        "normalizer = {}\n",
        "\n",
        "IOD = xml_all[['fname', 'GALLERY', 'IOD']].copy()\n",
        "IOD = pd.merge(peak_dict, IOD, left_index=True, right_on='fname')\n",
        "IOD['peak_indicator'] = (IOD['IOD']>IOD['peak_l']) & (IOD['IOD']<IOD['peak_r'])\n",
        "\n",
        "for fname in peak_dict.index:\n",
        "    normalizer[fname] = {}\n",
        "    normalizer[fname]['IOD_normalizer'] = np.median(xml_all.loc[(IOD['fname']==fname) & (IOD['peak_indicator']==True)]['IOD'])\n",
        "    normalizer[fname]['AREA_normalizer'] = np.median(xml_all.loc[(IOD['fname']==fname) & (IOD['peak_indicator']==True)]['AREA'])\n",
        "normalizer = pd.DataFrame.from_dict(normalizer, orient='index')\n",
        "\n",
        "normalizer.to_csv('normalizer.csv', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t7qnBtRua-W0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create a subset of data"
      ]
    },
    {
      "metadata": {
        "id": "rnSqs-CH2Nmv",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Randomly choose a balanced subset of data\n",
        "\n",
        "# read in all data\n",
        "xml_all = pd.read_csv('xml_all.csv', index_col='GUID')\n",
        "xml_all.drop(index=xml_all.loc[xml_all['GALLERY']>=4].index, inplace=True)\n",
        "xml_all\n",
        "if 'Grade' not in xml_all.columns:\n",
        "    xml_all = pd.merge(xml_all, labels, left_on='fname', right_index=True)\n",
        "xml_all = xml_all.drop(index=xml_all.loc[xml_all['Exclude']=='Yes'].index).drop(columns='Exclude')\n",
        "\n",
        "# sample some nuclei in each tumour grade\n",
        "temp = []\n",
        "nums = {'High': 5000, 'Low': 5000, 'Intermediate': 4206}\n",
        "for grade in ['High', 'Low', 'Intermediate']:\n",
        "    sample_index = np.random.choice(xml_all.loc[xml_all['Grade']==grade].shape[0], \n",
        "                                    nums[grade], replace=False)\n",
        "    temp.append(xml_all.loc[xml_all['Grade']==grade].iloc[sample_index])\n",
        "\n",
        "# normal samples\n",
        "normal_list = list(xml_all.loc[xml_all['Grade']=='Normal']['fname'].unique())\n",
        "normal_dict = {}\n",
        "for k in normal_list:\n",
        "    if k in ['11 2946 4', '44   14 2896 6', '14 1380 C']:\n",
        "        normal_dict[k] = 'NA'\n",
        "    else:\n",
        "        normal_dict[k] = k[8:]\n",
        "normal_dict = pd.DataFrame.from_dict(normal_dict, orient='index')\n",
        "normal_dict.columns=['Normal Type']\n",
        "\n",
        "# lymph node sample\n",
        "exclude = ['18 2301 Testis', '14 2565 Lymph node', '11 2946 4']\n",
        "normal_df = pd.merge(xml_all.loc[(xml_all['Grade']=='Normal') & (xml_all['fname'].map(lambda x: x not in exclude))], \n",
        "                     normal_dict, how='left', left_on='fname', right_index=True)\n",
        "\n",
        "N = 5000\n",
        "sample_index = np.random.choice(normal_df.shape[0], N, replace=False)\n",
        "temp.append(normal_df.iloc[sample_index])\n",
        "    \n",
        "temp = pd.concat(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Q49W7LNabe0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PCA Visualization"
      ]
    },
    {
      "metadata": {
        "id": "88FniFHSaa9G",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Run PCA and plot\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(df_data.drop(['fname', 'GALLERY', 'Grade', 'Normal Type'], axis=1).values)\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(x_scaled)\n",
        "\n",
        "df_pca = df_data[['Grade', 'IOD']].copy()\n",
        "\n",
        "df_pca['pca-one'] = pca_result[:,0]\n",
        "df_pca['pca-two'] = pca_result[:,1]\n",
        "\n",
        "# plot with no color\n",
        "\n",
        "grades = ['High','Intermediate','Low','Normal']\n",
        "sns.lmplot('pca-one', 'pca-two', data=df_pca,col='Grade', markers='x', \n",
        "           col_order=grades, fit_reg=False, scatter_kws={'alpha':0.2})\n",
        "plt.suptitle('PCA Output')\n",
        "plt.subplots_adjust(top=0.85)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oLFENqtB2Is1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# t-SNE Visualization"
      ]
    },
    {
      "metadata": {
        "id": "7qqScNswYgWv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "current_palette = sns.color_palette()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eDrjz_Zoc0uK",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title normalize\n",
        "\n",
        "def normalize(df):\n",
        "    normalizer = pd.read_csv('normalizer.csv', index_col=0)\n",
        "    df_copy = pd.merge(df, normalizer, left_on='fname', right_index=True)\n",
        "\n",
        "    # normalize IOD and AREA by normalizers\n",
        "\n",
        "    df_copy['IOD'] /= df_copy['IOD_normalizer']\n",
        "    df_copy['AREA'] /= df_copy['AREA_normalizer']\n",
        "    \n",
        "    df_copy.reindex(df.index)\n",
        "    \n",
        "    df_copy['IOD'] = np.log2(df_copy['IOD'])\n",
        "    df_copy['AREA'] = np.log2(df_copy['AREA'])\n",
        "    \n",
        "    # remove the normalizer columns\n",
        "    del df_copy['IOD_normalizer']\n",
        "    del df_copy['AREA_normalizer']\n",
        "    return df_copy\n",
        "\n",
        "df_data = normalize(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RcFnZG7n2hqE",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Scale, run t-SNE and visualize\n",
        "\n",
        "# transform using min-max scaler\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(df_data.drop(['fname', 'GALLERY', 'Grade', 'Normal Type'], axis=1).values)\n",
        "\n",
        "# run t-SNE\n",
        "\n",
        "tsne = TSNE(n_components=2, verbose=1, n_iter=3000, init='pca', perplexity=30)\n",
        "tsne_results = tsne.fit_transform(x_scaled)\n",
        "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
        "\n",
        "df_tsne = df_data.copy()\n",
        "df_tsne['x-tsne'] = tsne_results[:,0]\n",
        "df_tsne['y-tsne'] = tsne_results[:,1]\n",
        "\n",
        "# draw plot (no color)\n",
        "\n",
        "sns.set(font_scale=1.2, palette=current_palette)\n",
        "\n",
        "grades = ['High','Intermediate','Low','Normal']\n",
        "sns.lmplot('x-tsne', 'y-tsne', data=df_tsne, col='Grade', markers='x',\n",
        "           col_order=grades, fit_reg=False, scatter_kws={'alpha':0.2})\n",
        "plt.suptitle('t-SNE Output (perplexity=%d)' % 30)\n",
        "plt.subplots_adjust(top=0.85)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VFU1a8_UnPuh",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Visualize and color by normalized IOD\n",
        "\n",
        "df = df_data[['Grade', 'IOD']].copy()\n",
        "\n",
        "df['x-tsne'] = df_tsne['x-tsne']\n",
        "df['y-tsne'] = df_tsne['y-tsne']\n",
        "\n",
        "xmin = df['x-tsne'].min()-5\n",
        "xmax = df['x-tsne'].max()+5\n",
        "ymin = df['y-tsne'].min()-5\n",
        "ymax = df['y-tsne'].max()+5\n",
        "\n",
        "cmap = sns.cubehelix_palette(as_cmap=True)\n",
        "f,ax=plt.subplots(figsize=(27.5,5.5))\n",
        "grades = ['High','Intermediate','Low','Normal']\n",
        "for i in range(4):\n",
        "    plt.subplot(1,4,i+1)\n",
        "    if i==0:\n",
        "        points = plt.scatter(df.loc[df['Grade']==grades[i]]['x-tsne'], df.loc[df['Grade']==grades[i]]['y-tsne'], marker='x',\n",
        "                            c=np.clip(df.loc[df['Grade']==grades[i]]['IOD'],a_min=-1,a_max=3), s=50, cmap=cmap, alpha=0.2)\n",
        "    else:\n",
        "        plt.scatter(df.loc[df['Grade']==grades[i]]['x-tsne'], df.loc[df['Grade']==grades[i]]['y-tsne'],  marker='x',\n",
        "                    c=np.clip(df.loc[df['Grade']==grades[i]]['IOD'],a_min=-1,a_max=3), s=50, cmap=cmap, alpha=0.2)\n",
        "    plt.xlim(xmin,xmax)\n",
        "    plt.ylim(ymin,ymax)\n",
        "    plt.title('Grade: '+grades[i])\n",
        "    \n",
        "cbar_ax = f.add_axes([0.92, 0.15, 0.01, 0.7])\n",
        "f.colorbar(points, cax=cbar_ax)\n",
        "plt.suptitle('t-SNE Output coloured by normalized IOD (perplexity=30)')\n",
        "plt.subplots_adjust(top=0.85)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ulmVgapg-mOQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Contrastive PCA Visualization"
      ]
    },
    {
      "metadata": {
        "id": "Qyn8fetE-op1",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title set up\n",
        "from contrastive import CPCA\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(df_data.drop(['fname', 'GALLERY', 'Grade', 'Normal Type'], axis=1).values)\n",
        "\n",
        "cpca = CPCA(standardize=False)\n",
        "foreground_data = x_scaled[df_tsne['Grade']!='Normal']\n",
        "background_data = x_scaled[df_tsne['Grade']=='Normal']\n",
        "\n",
        "cpca.fit(foreground_data, background_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5SinxaS_Xk2m",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Try different values of alpha\n",
        "proj, alphas = cpca.transform(x_scaled, alpha_selection='all', n_alphas=10, max_log_alpha=1, return_alphas=True)\n",
        "df = df_tsne.copy()\n",
        "for coords, alpha in zip(proj, alphas):\n",
        "    df['x'] = coords[:,0]\n",
        "    df['y'] = coords[:,1]\n",
        "    sns.lmplot('x', 'y', data=df, col='Grade', hue='region', fit_reg=False)\n",
        "    plt.suptitle('%.3f' % alpha)\n",
        "    plt.xlim(df['x'].min(),df['x'].max())\n",
        "    plt.xlim(df['y'].min(),df['y'].max())\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YXmxBzbVX4ii",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title select one value and plot\n",
        "proj = cpca.transform(x_scaled, alpha_selection='manual', alpha_value=2.424)\n",
        "\n",
        "df = df_data[['Grade', 'IOD']].copy()\n",
        "\n",
        "df['x-cpca'] = proj[:,0]\n",
        "df['y-cpca'] = proj[:,1]\n",
        "\n",
        "xmin = df['x-cpca'].min()\n",
        "xmax = df['x-cpca'].max()\n",
        "ymin = df['y-cpca'].min()\n",
        "ymax = df['y-cpca'].max()\n",
        "\n",
        "# plot with no color\n",
        "\n",
        "df = df_data[['Grade', 'IOD']].copy()\n",
        "\n",
        "df['x-cpca'] = proj[:,0]\n",
        "df['y-cpca'] = proj[:,1]\n",
        "\n",
        "sns.set(font_scale=1.2)\n",
        "grades = ['High','Intermediate','Low','Normal']\n",
        "sns.lmplot('x-cpca', 'y-cpca', data=df,col='Grade', markers='x', \n",
        "           col_order=grades, fit_reg=False, scatter_kws={'alpha':0.2})\n",
        "plt.suptitle('cPCA Output (alpha=%.3f)' % 2.424)\n",
        "plt.subplots_adjust(top=0.85)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# colour by IOD\n",
        "cmap = sns.cubehelix_palette(as_cmap=True)\n",
        "f,ax=plt.subplots(figsize=(27.5,5.5))\n",
        "grades = ['High','Intermediate','Low','Normal']\n",
        "for i in range(4):\n",
        "    plt.subplot(1,4,i+1)\n",
        "    if i==0:\n",
        "        points = plt.scatter(df.loc[df['Grade']==grades[i]]['x-cpca'], df.loc[df['Grade']==grades[i]]['y-cpca'], marker='x',\n",
        "                            c=np.clip(df.loc[df['Grade']==grades[i]]['IOD'],a_min=-1,a_max=3), s=50, cmap=cmap, alpha=0.2)\n",
        "    else:\n",
        "        plt.scatter(df.loc[df['Grade']==grades[i]]['x-cpca'], df.loc[df['Grade']==grades[i]]['y-cpca'], marker='x',\n",
        "                    c=np.clip(df.loc[df['Grade']==grades[i]]['IOD'],a_min=-1,a_max=3), s=50, cmap=cmap, alpha=0.2)\n",
        "    plt.xlim(xmin,xmax)\n",
        "    plt.ylim(ymin,ymax)\n",
        "    plt.title('Grade: '+grades[i])\n",
        "    \n",
        "cbar_ax = f.add_axes([0.92, 0.15, 0.01, 0.7])\n",
        "f.colorbar(points, cax=cbar_ax)\n",
        "plt.suptitle('cPCA Output coloured by normalized IOD (alpha=2.424)')\n",
        "plt.subplots_adjust(top=0.85)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8jl4Knzq2gd7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Label abnormal clusters"
      ]
    },
    {
      "metadata": {
        "id": "53s8iCtC23kD",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title specify vertices of the abnormal regions\n",
        "\n",
        "coords1 = [(-100,100),(-66,40),(-3,60), (0,120), (120,160), (-100,160), (-80,120)]\n",
        "\n",
        "coords3 = [(25,50),(35,47),(46,53),(55,83),(42,81),(33,73),(25,57)]\n",
        "\n",
        "p = Point(5, -5)\n",
        "x = p.buffer(15)\n",
        "s = x.simplify(0.02, preserve_topology=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JaERf2xnjaN1",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title label each point\n",
        "\n",
        "# region 1\n",
        "polygon1 = Polygon(coords1)\n",
        "# region 3\n",
        "polygon3 = Polygon(coords3)\n",
        "\n",
        "df_tsne['region'] = np.zeros(df_tsne.shape[0], dtype=np.int32)\n",
        "for guid in df_tsne.index:\n",
        "    point = Point(df_tsne.loc[guid,'x-tsne'], df_tsne.loc[guid,'y-tsne'])\n",
        "    if polygon1.contains(point):\n",
        "        df_tsne.loc[guid,'region'] = 1\n",
        "    elif s.contains(point):\n",
        "        df_tsne.loc[guid,'region'] = 2\n",
        "    elif polygon3.contains(point):\n",
        "        df_tsne.loc[guid,'region'] = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a0Fo9ruZj2vL",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Visualize labels\n",
        "\n",
        "grades = ['High','Intermediate','Low','Normal']\n",
        "lm = sns.lmplot('x-tsne', 'y-tsne', data=df_tsne, col='Grade', \n",
        "           markers='x', hue='region',\n",
        "           col_order=grades, fit_reg=False, scatter_kws={'alpha':0.3, 's':20}, size=4, aspect=0.9)\n",
        "plt.suptitle('Target t-SNE Output (test data)')\n",
        "plt.subplots_adjust(top=0.8)\n",
        "for lh in lm._legend.legendHandles:\n",
        "    lh.set_alpha(1)\n",
        "    lh._sizes = [50]\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-kWbg-AK24WH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train fully connected multi-task neural network\n",
        "Learn the embedding function and classify nuclei into clusters at the same time"
      ]
    },
    {
      "metadata": {
        "id": "d5vPvl2wdk_P",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Import and normalize data\n",
        "\n",
        "# read saved data\n",
        "temp = pd.read_csv('temporary files/data_final.csv', \n",
        "                   index_col='GUID', dtype={'Normal Type':str})\n",
        "df_tsne = pd.read_csv('temporary files/outputs_tsne_final.csv', \n",
        "                      index_col='GUID', dtype={'Normal Type':str})\n",
        "\n",
        "normalizer = pd.read_csv('normalizer.csv', index_col=0)\n",
        "\n",
        "temp = pd.merge(temp, normalizer, left_on='fname', right_index=True)\n",
        "\n",
        "# normalize IOD and AREA by normalizers\n",
        "\n",
        "temp['IOD'] /= temp['IOD_normalizer']\n",
        "temp['AREA'] /= temp['AREA_normalizer']\n",
        "\n",
        "temp = temp.reindex(df_tsne.index)\n",
        "\n",
        "# remove the normalizer columns\n",
        "del temp['IOD_normalizer']\n",
        "del temp['AREA_normalizer']\n",
        "del normalizer\n",
        "\n",
        "temp['IOD'] = np.log2(temp['IOD'])\n",
        "temp['AREA'] = np.log2(temp['AREA'])\n",
        "print(temp['IOD'].median(), temp['AREA'].median())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2PHe9tYxBupA",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title scale inputs\n",
        "\n",
        "df_data = df_tsne.drop(columns=['fname','GALLERY','Grade','PWS Classification','IODbin','region','Normal Type'])\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "for col in df_data.columns:\n",
        "    if col not in ['x-tsne', 'y-tsne']:\n",
        "        df_data[col] = min_max_scaler.fit_transform(df_data[col].values.reshape(-1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lIbC6tIE-VPj",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title For each grade, randomly sample 2/3 of the indices for training set, 1/6 for validation and remaining 1/6 for test\n",
        "grade = 'High'\n",
        "train_index = np.random.choice(temp.reset_index().loc[(temp['Grade']==grade).values].index.values, \n",
        "                               size=int(2/3*temp.loc[temp['Grade']==grade].shape[0]),  \n",
        "                               replace=False)\n",
        "for grade in ['Intermediate', 'Low', 'Normal']:\n",
        "    train_index = np.concatenate([train_index, \n",
        "                                  np.random.choice(temp.reset_index().loc[(temp['Grade']==grade).values].index.values, \n",
        "                                                   size=int(2/3*temp.loc[(temp['Grade']==grade).values].shape[0]),  \n",
        "                                                   replace=False)])\n",
        "\n",
        "val_index = None\n",
        "test_index = None\n",
        "for grade in ['High', 'Intermediate', 'Low', 'Normal']:\n",
        "    df = temp.reset_index().loc[(temp['Grade']==grade).values]\n",
        "    remaining = list(set(df.index.values).difference(set(train_index)))\n",
        "    sample_val = np.random.choice(remaining, int(0.5*len(remaining)), replace=False)\n",
        "    sample_test = np.array(list(set(remaining).difference(set(sample_val))), dtype=np.int32)\n",
        "    if val_index is None:\n",
        "        val_index = sample_val\n",
        "        test_index = sample_test\n",
        "    else:\n",
        "        val_index = np.concatenate([val_index, sample_val])\n",
        "        test_index = np.concatenate([test_index, sample_test])\n",
        "                     \n",
        "#test_index = np.array(list(set(np.arange(temp.shape[0])).difference(set(train_index))), dtype=np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OH2hRf7i-XIP",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title save indices\n",
        "np.save('temporary files/train_index.npy', train_index)\n",
        "np.save('temporary files/val_index.npy', val_index)\n",
        "np.save('temporary files/test_index.npy', test_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qZdu8TZWBmBW",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title retrieve indices\n",
        "train_index = np.load('temporary files/train_index.npy')\n",
        "val_index = np.load('temporary files/val_index.npy')\n",
        "test_index = np.load('temporary files/test_index.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yU1owazq8-_V",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Define DataSet object\n",
        "\n",
        "class DataSet(object):\n",
        "    def __init__(self,\n",
        "                 inputs,\n",
        "                 labels,\n",
        "                 aux_outputs=None,\n",
        "                 aux_inputs=None,\n",
        "                 balance_label=None):\n",
        "\n",
        "        assert len(inputs) == len(labels), (\n",
        "            'inputs len: %s labels.shape: %s' % (len(inputs), len(labels)))\n",
        "        self._num_examples = inputs.shape[0]\n",
        "        self._inputs = inputs\n",
        "        self._labels = labels\n",
        "        #self._epochs_completed = 0\n",
        "        #self._index_in_epoch = 0\n",
        "        self._index = np.arange(self._num_examples)\n",
        "        self._aux_outputs = aux_outputs\n",
        "        self._aux_inputs=aux_inputs\n",
        "        self._b = balance_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Xi1aLV1B2kD",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title use the indices to prepare data sets\n",
        "index = train_index\n",
        "train_data = DataSet(inputs=df_data.drop(columns=['x-tsne','y-tsne']).values[index],\n",
        "                     labels=df_data[['x-tsne', 'y-tsne']].values[index],\n",
        "                     aux_outputs=df_tsne['region'].values[index])\n",
        "index = val_index\n",
        "val_data = DataSet(inputs=df_data.drop(columns=['x-tsne','y-tsne']).values[index],\n",
        "                     labels=df_data[['x-tsne', 'y-tsne']].values[index],\n",
        "                     aux_outputs=df_tsne['region'].values[index])\n",
        "index = test_index\n",
        "test_data = DataSet(inputs=df_data.drop(columns=['x-tsne','y-tsne']).values[index],\n",
        "                     labels=df_data[['x-tsne', 'y-tsne']].values[index],\n",
        "                     aux_outputs=df_tsne['region'].values[index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PK-DVSff3R_i",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Define architecture\n",
        "layers = [61, 128, 256, 512, 1024, 1024, 512]\n",
        "y_trail = [256, 256, 128, 64]\n",
        "aux_trail = [256, 128]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LohEQsIAX59S",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Define model with Keras\n",
        "\n",
        "x_ = Input(shape=(layers[0],))\n",
        "\n",
        "x = x_\n",
        "i = 1\n",
        "for n in layers[1:]:\n",
        "    x = Dense(units=n, activation='relu', name='fc'+str(i)+'_'+str(n))(x)\n",
        "    #if i<len(layers)-2:\n",
        "    #    x = BatchNormalization()(x)\n",
        "    #x = Activation('relu')(x)\n",
        "    i += 1\n",
        "\n",
        "n = aux_trail[0]\n",
        "x_aux = Dense(units=n, activation='relu', name='aux_fc'+str(i)+'_'+str(n))(x)\n",
        "if len(aux_trail)>1:\n",
        "    for n in aux_trail[1:]:\n",
        "        x_aux = Dense(units=n, activation='relu', name='aux_fc'+str(i)+'_'+str(n))(x_aux)\n",
        "        i += 1\n",
        "aux_output = Dense(units=4, activation='softmax', name='aux_output')(x_aux)\n",
        "\n",
        "for n in y_trail:\n",
        "    x = Dense(units=n, activation='relu', name='fc'+str(i)+'_'+str(n))(x)\n",
        "    #if i<len(layers)-2:\n",
        "    #    x = BatchNormalization()(x)\n",
        "    #x = Activation('relu')(x)\n",
        "    i += 1\n",
        "y = Dense(units=2, name='fc_final')(x)\n",
        "\n",
        "model = Model(inputs=x_, outputs=[y, aux_output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ZUXwIAgYAuY",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Define my f1 metric\n",
        "import keras.backend as K\n",
        "def myF1(y_true, y_pred):\n",
        "    #val_targ = K.argmax(y_true) \n",
        "    val_predict = K.argmax(y_pred, axis=1)\n",
        "    \n",
        "    f1 = 0\n",
        "    real_positives = K.sum(y_true, axis=0)\n",
        "    for c in range(4):\n",
        "        y_pred_c = K.cast(K.equal(val_predict, c), 'float32')\n",
        "        \n",
        "        true_positives = K.sum(y_true[:,c] * y_pred_c)\n",
        "        prec = true_positives / (real_positives[c] + K.epsilon())\n",
        "        \n",
        "        predicted_positives = K.sum(y_pred_c)\n",
        "        rec = true_positives / (predicted_positives + K.epsilon())\n",
        "        \n",
        "        f1 += 2 * (prec*rec) /(prec + rec + K.epsilon())\n",
        "    return f1/4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "naPGkz_uYHLq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_name_prefix = 'NN_model_v0'\n",
        "def reset_log():\n",
        "    return {'train':[], 'val':[]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b78LgfeTYKNY",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title define metrics callback\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "class Metrics(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self._f1score = 0.9\n",
        "        if len(self.model.inputs)>1:\n",
        "            self._aux_in = True\n",
        "        else:\n",
        "            self._aux_in = False\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if self._aux_in:\n",
        "            val_predict = np.argmax(self.model.predict(self.validation_data[:2])[1], axis=1)\n",
        "            n = 3\n",
        "        else:\n",
        "            val_predict = np.argmax(self.model.predict(self.validation_data[0])[1], axis=1)\n",
        "            train_predict = np.argmax(self.model.predict(train_data._inputs)[1], axis=1)\n",
        "            _train_f1 = f1_score(train_data._aux_outputs, \n",
        "                                 train_predict, average='macro')\n",
        "            F1_log['train'].append(_train_f1)\n",
        "            n = 2\n",
        "        \n",
        "        val_targ = np.argmax(self.validation_data[n],axis=1)\n",
        "        _val_f1 = f1_score(val_targ, val_predict, average='macro')\n",
        "        \n",
        "        F1_log['val'].append(_val_f1)\n",
        "                \n",
        "        print(' â€” val_f1: %f' % _val_f1)\n",
        "        if _val_f1>self._f1score:\n",
        "            file = 'Keras models/NonCNN/'+model_name_prefix+'_f%.3f_%.3f.h5' % (_val_f1, logs['val_fc_final_loss'])\n",
        "            print('saving model at '+file)\n",
        "            self.model.save(file)\n",
        "            self._f1score = _val_f1\n",
        "        return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A9JF11POYQvM",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Configure callbacks\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', mode='min', \n",
        "                              factor=0.5, patience=3, \n",
        "                              verbose=1, min_lr=1e-7)\n",
        "metrics = Metrics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h0HxJYoMYkBv",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Compile model\n",
        "F1_log = reset_log()\n",
        "model.compile(optimizer='adam', #'RMSProp','adam'\n",
        "              loss=['mean_absolute_error', 'categorical_crossentropy'], \n",
        "              loss_weights=[0.001, 1.],\n",
        "              metrics={'aux_output': myF1}) #optimizers.Adam(lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uBruSDW9YmN7",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Train\n",
        "\n",
        "hist = model.fit(train_data._inputs, \n",
        "              [train_data._labels, to_categorical(train_data._aux_outputs, num_classes=4)], \n",
        "              epochs=500, batch_size=128, shuffle=True, \n",
        "              validation_data=(val_data._inputs, \n",
        "                               [val_data._labels, to_categorical(val_data._aux_outputs, num_classes=4)]),\n",
        "              #sample_weight= [sample_weights] * 2,\n",
        "              callbacks=[reduce_lr, metrics]) # , checkpointer ,initial_epoch=100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oAcGDZO_HA8r",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title plot learning curve for f1 score\n",
        "\n",
        "plt.rc('xtick', labelsize=12)\n",
        "plt.plot(F1_log['train'], label='on training set')\n",
        "plt.rc('ytick', labelsize=12)\n",
        "plt.plot(F1_log['val'], label='on validation set')\n",
        "plt.xlabel('epoch',fontsize=15)\n",
        "plt.ylabel('macro F1 score',fontsize=15)\n",
        "plt.legend()\n",
        "plt.ylim(min(0.6, min(F1_log['train'])-0.02, min(F1_log['val'])-0.02),1.02)\n",
        "if model.loss_weights[0]==0:\n",
        "    plt.title('Training log of macro F1 score (single-task)',fontsize=15)\n",
        "else:\n",
        "    plt.title('Training log of macro F1 score (multi-task)',fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QyoD4ZPDHJni",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title plot learning curve for mean absolute loss\n",
        "\n",
        "plt.rc('xtick', labelsize=12)\n",
        "plt.plot(hist.history['fc_final_loss'], label='on training set')\n",
        "plt.rc('ytick', labelsize=12)\n",
        "plt.plot(hist.history['val_fc_final_loss'], label='on validation set')\n",
        "plt.xlabel('epoch',fontsize=15)\n",
        "plt.ylabel('mean absolute loss',fontsize=15)\n",
        "plt.ylim(2,20)\n",
        "plt.legend()\n",
        "plt.title('Training log of mean absolute loss',fontsize=15)\n",
        "#plt.gca().set_ylim(3, 4)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VBkUP-e0HRsb",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title plot learning curve for categorical crossentropy loss\n",
        "\n",
        "plt.rc('xtick', labelsize=12)\n",
        "plt.semilogy(hist.history['loss'], label='on training set')\n",
        "plt.rc('ytick', labelsize=12)\n",
        "plt.semilogy(hist.history['val_loss'], label='on validation set')\n",
        "plt.xlabel('epoch',fontsize=15)\n",
        "plt.ylabel('cross entropy loss',fontsize=15)\n",
        "#plt.rcParams.update({'font.size': 20})\n",
        "plt.gca().set_ylim(0.001,1)\n",
        "plt.legend()\n",
        "if model.loss_weights[0]==0:\n",
        "    plt.title('Training log of categorical cross entropy loss (single-task)',fontsize=15)\n",
        "else:\n",
        "    plt.title('Training log of categorical cross entropy loss (multi-task)',fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zps3ilx9Y-WY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model evaluation"
      ]
    },
    {
      "metadata": {
        "id": "dydXlE_XZBBq",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Load model\n",
        "model_name = 'NN_model_v35_f0.947_5.150'\n",
        "model = load_model('Keras models/NonCNN/'+model_name, custom_objects={'myF1': myF1})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2nZHYzKUZEQT",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title evaluate on test data\n",
        "\n",
        "outputs = model.predict(test_data._inputs, batch_size=128, verbose=1) #[:val_data._b.shape[0]]\n",
        "\n",
        "df = df_tsne.iloc[test_index].copy()\n",
        "\n",
        "df['x-model'] = outputs[0][:, 0]\n",
        "df['y-model'] = outputs[0][:, 1]\n",
        "df['region-model'] = np.argmax(outputs[1], axis=1)\n",
        "\n",
        "print(np.mean(df['region-model']==df['region']))\n",
        "print(f1_score(df['region'], df['region-model'], average='macro'))\n",
        "print(classification_report(df['region'], df['region-model'], labels=[0,1,2,3],\n",
        "                           target_names=['region'+str(i) for i in range(4)], digits = 3))\n",
        "pd.crosstab(df['region-model'], df['region'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oe_t9jgXH62g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(x=test_data._inputs, y=[test_data._labels, to_categorical(test_data._aux_outputs, num_classes=4)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PyEZBPBcIOF-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualize model output"
      ]
    },
    {
      "metadata": {
        "id": "eCC8Y6FrIQSm",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title plot the original t-SNE\n",
        "\n",
        "sns.lmplot( x='x-tsne', y='y-tsne', data=df_tsne.iloc[test_index], fit_reg=False, \n",
        "            hue='region', col='Grade', col_order=['High','Intermediate','Low','Normal'],\n",
        "            markers='x', scatter_kws={'alpha':0.4})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zU0kA8VJIdS0",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title plot the output (test data)\n",
        "\n",
        "outputs = model.predict(test_data._inputs, batch_size=128, verbose=1)\n",
        "\n",
        "df = df_tsne.iloc[test_index].copy()\n",
        "\n",
        "df['x-model'] = outputs[0][:, 0]\n",
        "df['y-model'] = outputs[0][:, 1]\n",
        "df['region-model'] = np.argmax(outputs[1], axis=1)\n",
        "\n",
        "sns.lmplot( x='x-model', y='y-model', data=df, fit_reg=False, \n",
        "            hue='region-model', col='Grade', col_order=['High','Intermediate','Low','Normal'],\n",
        "            markers='x', scatter_kws={'alpha':0.4}) \n",
        "plt.show()\n",
        "\n",
        "sns.lmplot( x='x-model', y='y-model', data=df, fit_reg=False, \n",
        "            hue='region', col='Grade', col_order=['High','Intermediate','Low','Normal'],\n",
        "            markers='x', scatter_kws={'alpha':0.4}) \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8XFLGye0IvEd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get model outputs for all data"
      ]
    },
    {
      "metadata": {
        "id": "KPLPIf1vIx71",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title read in all XML data\n",
        "xml_all = pd.read_csv('xml_all.csv', index_col='GUID')\n",
        "\n",
        "xml_all.drop(index=xml_all.loc[xml_all['GALLERY']>=4].index, inplace=True)\n",
        "\n",
        "xml_all = pd.merge(labels, xml_all, left_index=True, right_on='fname')\n",
        "xml_all = xml_all.drop(index=xml_all.loc[xml_all['Exclude']=='Yes'].index).drop(columns='Exclude')\n",
        "\n",
        "xml_all = xml_all[df_tsne.drop(columns=['IODbin', 'Normal Type', 'PWS Classification', 'region', 'x-tsne', 'y-tsne']).columns.tolist()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LuWnzhc9JGPK",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title normalize\n",
        "\n",
        "normalizer = pd.read_csv('normalizer.csv', index_col=0)\n",
        "\n",
        "modelOutputs = xml_all.copy()\n",
        "modelOutputs = pd.merge(modelOutputs, normalizer, left_on='fname', right_index=True)\n",
        "\n",
        "# normalize IOD and AREA by normalizers\n",
        "\n",
        "modelOutputs['IOD'] /= modelOutputs['IOD_normalizer']\n",
        "modelOutputs['AREA'] /= modelOutputs['AREA_normalizer']\n",
        "\n",
        "modelOutputs = modelOutputs.reindex(xml_all.index)\n",
        "\n",
        "# remove the normalizer columns\n",
        "del modelOutputs['IOD_normalizer']\n",
        "del modelOutputs['AREA_normalizer']\n",
        "del normalizer\n",
        "\n",
        "modelOutputs['IOD'] = np.log2(modelOutputs['IOD'])\n",
        "modelOutputs['AREA'] = np.log2(modelOutputs['AREA'])\n",
        "print(modelOutputs['IOD'].median(), modelOutputs['AREA'].median())\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "min_max_scaler.fit(temp.drop(['fname', 'GALLERY', 'Grade', 'Normal Type'], axis=1).values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WGsIPb-hJJsA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "using_aux_output = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t-VTsSqMJYNx",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title save model outputs for each sample\n",
        "\n",
        "modelOutputs['x-model'] = np.zeros(modelOutputs.shape[0])\n",
        "modelOutputs['y-model'] = np.zeros(modelOutputs.shape[0])\n",
        "modelOutputs['region-model'] = np.zeros(modelOutputs.shape[0])\n",
        "for a in range(4):\n",
        "    modelOutputs['prop'+str(a)] = np.zeros(modelOutputs.shape[0])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "# feed into model to obtain outputs\n",
        "outputs = model.predict(min_max_scaler.transform(modelOutputs[xml_all.drop(columns=['fname','GALLERY', 'Grade']).columns.tolist()].values), \n",
        "                        batch_size=batch_size, verbose=1)\n",
        "\n",
        "if using_aux_output:\n",
        "    modelOutputs['x-model'] = outputs[0][:, 0]\n",
        "    modelOutputs['y-model'] = outputs[0][:, 1]\n",
        "    for a in range(4):\n",
        "        modelOutputs['prop'+str(a)] = outputs[1][:,a]\n",
        "    modelOutputs['region-model'] = np.argmax(outputs[1],axis=1)\n",
        "else:\n",
        "    modelOutputs['x-model'] = outputs[:, 0]\n",
        "    modelOutputs['y-model'] = outputs[:, 1]\n",
        "    \n",
        "# save model outputs\n",
        "modelOutputs[['x-model','y-model','region-model', \n",
        "              'fname', 'GALLERY', 'Grade'] + ['prop'+str(i) for i in range(4)]].to_csv('modelOutputs.csv', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nIEN8md_KAtN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generate sample profiles"
      ]
    },
    {
      "metadata": {
        "id": "adpc7IMIJpk7",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title get model outputs\n",
        "modelOutputs = pd.read_csv('modelOutputs.csv', index_col='GUID')\n",
        "\n",
        "print(modelOutputs['x-model'].min(), modelOutputs['x-model'].max())\n",
        "print(modelOutputs['y-model'].min(), modelOutputs['y-model'].max())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JdT-nX4cKFmK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xy = [(-180, 155), (-130, 140)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LBWKB9d8KNn3",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title generate sample profiles\n",
        "\n",
        "cwd = os.getcwd()\n",
        "on_cloud = cwd.startswith(r'/home/liyunlu3')\n",
        "\n",
        "for fname in xml_all['fname'].unique():\n",
        "    \n",
        "    # feed into CNN to obtain outputs\n",
        "    df = modelOutputs.loc[modelOutputs['fname']==fname][['Grade', 'region-model', 'x-model', 'y-model']]\n",
        "    \n",
        "    sns.lmplot( x='x-model', y='y-model', data=df, fit_reg=False, hue='region-model',\n",
        "                markers='x', scatter_kws={'alpha':0.2})\n",
        "    title = '('+labels.loc[fname,'Grade']+' Grade) '+fname\n",
        "    plt.xlim(xy[0][0], xy[0][1])\n",
        "    plt.ylim(xy[1][0], xy[1][1])\n",
        "    plt.title(title)\n",
        "    plt.subplots_adjust(top=0.9)\n",
        "    #plt.savefig('Visuals/sample profiles/'+title+'.png')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PjF4C-Ga8Epo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Integrating with clinical and genetic data"
      ]
    },
    {
      "metadata": {
        "id": "2IX1XBQB8Jv_",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Import data\n",
        "\n",
        "# get neural network outputs for all nuclei\n",
        "modelOutputs = pd.read_csv('modelOutputs.csv', index_col='GUID')\n",
        "\n",
        "# get labels for high grade included samples only\n",
        "wb = openpyxl.load_workbook('file_list.xlsx', read_only=True, data_only=True)\n",
        "ws = wb['file_list']\n",
        "labels = {}\n",
        "for i in range(1, ws.max_row+1):\n",
        "    fname = ws['A'+str(i+1)].value\n",
        "    if fname is None:\n",
        "        break\n",
        "    labels[fname] = {'Grade': ws['F'+str(i+1)].value, \n",
        "                     'Exclude': ws['G'+str(i+1)].value,\n",
        "                     'Pathology.No':ws['C'+str(i+1)].value[:7].replace(' ','--')}\n",
        "wb.close()\n",
        "del wb\n",
        "del ws\n",
        "\n",
        "labels = pd.DataFrame(labels).transpose()\n",
        "labels.drop(index=labels.loc[(labels['Exclude']=='Yes')|(labels['Grade']!='High')].index, inplace=True)\n",
        "labels.drop(columns=['Exclude', 'Grade'], inplace=True) \n",
        "# all matched samples must be high grade, so drop other grades\n",
        "\n",
        "\n",
        "# get survival variables data\n",
        "\n",
        "survival = pd.read_csv('survivalVariables.csv', index_col='Pathology.No')\n",
        "survival.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VmR5jrFyK3x4",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title aggregate into sample level features\n",
        "sample_features = pd.crosstab(modelOutputs['fname'], modelOutputs['region-model']).apply(lambda r: r/r.sum(), axis=1)\n",
        "sample_features.rename(columns={0:'region0', 1:'region1', 2:'region2', 3:'region3'}, inplace=True)\n",
        "print(sample_features.shape)\n",
        "\n",
        "#sample_features = sample_features.merge(modelOutputs[['fname','Grade']].groupby('fname').agg('first'), left_index=True, right_index=True)\n",
        "sample_features['region-all'] = sample_features['region1']+sample_features['region2']+sample_features['region3']\n",
        "#plt.hist(sample_features['region3'], 30)\n",
        "#plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dqKijL7y825u",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title aggregate into tumour level features\n",
        "tumour_features = pd.crosstab(modelOutputs['Pathology.No'], modelOutputs['region-model']).apply(lambda r: r/r.sum(), axis=1)\n",
        "tumour_features.rename(columns={0:'region0', 1:'region1', 2:'region2', 3:'region3'}, inplace=True)\n",
        "print(tumour_features.shape)\n",
        "\n",
        "tumour_features['region-all'] = tumour_features['region1']+tumour_features['region2']+tumour_features['region3']\n",
        "#plt.hist(tumour_features['region1'], 30)\n",
        "#plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jthTSPYnK9W3",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title save features\n",
        "sample_features.to_csv('region_features.csv', sep=',')\n",
        "tumour_features.to_csv('region_features_by_tumour.csv', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_kNJEa8hLDiH",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title get Relative proportions\n",
        "\n",
        "for col in ['region'+str(i) for i in range(1,4)]:\n",
        "    combined[col] /= combined['region-all']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "87Zw0ozhMZt9",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title plot scatter plot\n",
        "\n",
        "region = 'region2'\n",
        "feature = 'overallSurvivalTime'\n",
        "cat = 'CDKN2A'\n",
        "\n",
        "df = combined[[region, feature, cat, 'dead', 'Nature']].dropna(how='any').copy()\n",
        "df[region] = np.sqrt(combined[region])\n",
        "df[feature] = np.sqrt(combined[feature])\n",
        "print(df[region].corr(df[feature]))\n",
        "sns.lmplot(region, feature, data=df, fit_reg=False, hue='Nature')\n",
        "plt.show()\n",
        "\n",
        "for c in df[cat].unique():\n",
        "    print(cat + ' ' + str(c) + ':', df[region].loc[df[cat]==c].corr(df[feature].loc[df[cat]==c]))\n",
        "sns.lmplot(region, feature, data=df, col=cat, fit_reg=False, hue='Nature')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tHqtEBNQiiyv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Image Data Formatting"
      ]
    },
    {
      "metadata": {
        "id": "CrT6ydoGioFk",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Define function to split image\n",
        "def split(directory):\n",
        "    # read image\n",
        "    image = img.imread(directory)\n",
        "    \n",
        "    # identify a mask based on RGB (all=1):\n",
        "    mask0 = (image[:,:,0] < 1)\n",
        "    \n",
        "    # identify another mask based on aligned bounding box:\n",
        "    # scan vertically\n",
        "    mask1 = np.zeros(image.shape[:2], dtype=np.int64)\n",
        "    row_mask = image[:,:,0].mean(axis=1)<1\n",
        "    row_index, N_rows = ndimage.label(row_mask)\n",
        "    \n",
        "    # check vertical splits\n",
        "    relabel = False\n",
        "    for i in range(2,N_rows+1):\n",
        "        n_start = np.arange(image.shape[0])[row_index==(i-1)].max()+1\n",
        "        n_end = np.arange(image.shape[0])[row_index==i].min()\n",
        "        if n_end - n_start<5:\n",
        "            row_mask[n_start:n_end] = 1\n",
        "            # print(n_start,n_end)\n",
        "            relabel = True\n",
        "    if relabel:\n",
        "        row_index, N_rows = ndimage.label(row_mask)\n",
        "    \n",
        "    #scan horizontally\n",
        "    n = 0\n",
        "    for i in range(1,N_rows+1):\n",
        "        row_height = np.sum(row_index==i)\n",
        "        col_mask = (image[:,:,0][row_index==i].mean(axis=0) < 1) + 0\n",
        "        \n",
        "        # check horizontal splits\n",
        "        col_index, N_cols = ndimage.label(col_mask)\n",
        "        for j in range(2,N_cols+1):\n",
        "            n_start = np.arange(image.shape[1])[col_index==(j-1)].max()+1\n",
        "            n_end = np.arange(image.shape[1])[col_index==j].min()\n",
        "            if n_end - n_start<5:\n",
        "                col_mask[n_start:n_end] = 1\n",
        "        mask1[row_index==i] = col_mask.reshape(1,-1)\n",
        "    \n",
        "    # use the second mask to identify the correct label for each patch\n",
        "    # then use the first mask to refine the labelled patches\n",
        "    label, _ = ndimage.label(mask1)\n",
        "    label = np.multiply(label, mask0)\n",
        "    \n",
        "    # extract the slices from the labels\n",
        "    slices = ndimage.find_objects(label)\n",
        "    return [image[i_slice] for i_slice in slices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1I7Q6rodi2M9",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title get the indices information\n",
        "\n",
        "wb = openpyxl.load_workbook(main_path + 'Image data logistics.xlsx', read_only=True, data_only=True)\n",
        "ws = wb.get_sheet_by_name('main')\n",
        "indices = {}\n",
        "for i in range(1, ws.max_row):\n",
        "    fname = ws['A'+str(i+1)].value\n",
        "    if ws['G'+str(i+1)].value is None:\n",
        "        break\n",
        "    indices[fname] = {}\n",
        "    n = ws['F'+str(i+1)].value\n",
        "    if n>1:\n",
        "        indices[fname]['b'] = ws['I'+str(i+1)].value\n",
        "        if n>2:\n",
        "            indices[fname]['c'] = ws['K'+str(i+1)].value\n",
        "            if n>3:\n",
        "                indices[fname]['d'] = ws['M'+str(i+1)].value\n",
        "wb.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kDE0Tfk7jIdd",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title format and save Gallery 1 images folder by folder\n",
        "suffices = ['a','b','c','d']\n",
        "for folder in os.listdir(main_path + 'Raw data\\\\image data'):\n",
        "    \n",
        "    for file in os.listdir('Raw data\\\\image data\\\\' + folder):\n",
        "        if file.endswith('.info'):\n",
        "            fname = file[:-5]\n",
        "            break\n",
        "    if fname not in list(indices.keys()):\n",
        "        print('file', fname, 'passed.')\n",
        "        continue\n",
        "    if os.path.exists(main_path + 'images\\\\' + fname):\n",
        "        print(fname, 'already created.')\n",
        "    else:\n",
        "        images = []\n",
        "        for suffix in suffices:\n",
        "            path = main_path + \"Raw data\\\\image data\\\\\" + folder + \"\\\\\" + fname + suffix + \".png\"\n",
        "            if os.path.isfile(path): \n",
        "                images.append(split(path))\n",
        "        if len(images) == 0:\n",
        "            print(\"Folder \" + folder + \" does not contain image file, or their names are incorrect\")\n",
        "        else:\n",
        "            # save images\n",
        "            directory = main_path + 'images\\\\' + fname\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "            n = 0\n",
        "            for i_sliced_im in images[0]:\n",
        "                n += 1\n",
        "                scipy.misc.imsave( directory + '\\\\' + fname + '_' + str(n) + '.png', i_sliced_im)\n",
        "            if len(images)>1:\n",
        "                \n",
        "                for i in range(1,len(images)):\n",
        "                    print(fname, suffices[i-1], len(images[0]), ' vs ', suffices[i], indices[fname][suffices[i]])\n",
        "                    plt.subplot(121)\n",
        "                    plt.imshow(images[i-1][-1])\n",
        "                    plt.subplot(122)\n",
        "                    plt.imshow(images[i][indices[fname][suffices[i]]-2])\n",
        "                    plt.show()\n",
        "                    for i_sliced_im in images[i][(indices[fname][suffices[i]]-1):]:\n",
        "                        n += 1\n",
        "                        scipy.misc.imsave( directory + '\\\\' + fname + '_' + str(n) + '.png', i_sliced_im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DBvWPb1W0ris",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title format and save Gallery 2-4 images\n",
        "# get the counts information\n",
        "\n",
        "wb = openpyxl.load_workbook(main_path + 'Image data logistics.xlsx', read_only=True, data_only=True)\n",
        "ws = wb.get_sheet_by_name('main')\n",
        "indices = {}\n",
        "for i in range(1, ws.max_row):\n",
        "    fname = ws['A'+str(i+1)].value\n",
        "    indices[fname] = ws['B'+str(i+1)].value\n",
        "wb.close()\n",
        "\n",
        "# save images\n",
        "stats = {}\n",
        "for folder in os.listdir(main_path + 'Raw data\\\\image data'):\n",
        "    for file in os.listdir('Raw data\\\\image data\\\\' + folder):\n",
        "        if file.endswith('.info'):\n",
        "            fname = file[:-5]\n",
        "            break\n",
        "    \n",
        "    directory = main_path + 'images\\\\' + fname\n",
        "    if not os.path.exists(directory):\n",
        "        print(fname, ' excluded.')\n",
        "    else:\n",
        "        stats[fname] = {}\n",
        "        n = len([name for name in os.listdir(directory)])\n",
        "        stats[fname][1] = n\n",
        "        for suffix in [2,3,4]:\n",
        "            path = main_path + \"Raw data\\\\image data\\\\\" + folder + \"\\\\\" + fname + '_G' + str(suffix) + \".png\"\n",
        "            if os.path.isfile(path): \n",
        "                images = split(path)\n",
        "                stats[fname][suffix] = len(images)\n",
        "                # save images\n",
        "                for i_sliced_im in images:\n",
        "                    n += 1\n",
        "                    scipy.misc.imsave( directory + '\\\\' + fname + '_' + str(n) + '.png', i_sliced_im)\n",
        "            else:\n",
        "                stats[fname][suffix] = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "52rHqCWN0x-b",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title match xml data with image names\n",
        "\n",
        "xml_all = pd.read_csv('xml_all.csv', index_col='GUID')\n",
        "xml_all.drop(index=xml_all.loc[xml_all['GALLERY']>=4].index, inplace=True)\n",
        "\n",
        "#get labels\n",
        "wb = openpyxl.load_workbook('file_list.xlsx', read_only=True, data_only=True)\n",
        "ws = wb['file_list']\n",
        "labels = {}\n",
        "for i in range(1, ws.max_row+1):\n",
        "    fname = ws['A'+str(i+1)].value\n",
        "    if fname is None:\n",
        "        break\n",
        "    labels[fname] = {'Grade': ws['F'+str(i+1)].value, 'Exclude': ws['G'+str(i+1)].value}\n",
        "wb.close()\n",
        "\n",
        "labels = pd.DataFrame(labels).transpose()\n",
        "#labels = labels.drop(index=labels[labels['Exclude']=='Yes'].index).drop(columns='Exclude')\n",
        "\n",
        "xml_all = pd.merge(labels, xml_all, left_index=True, right_on='fname')\n",
        "xml_all = xml_all.drop(index=xml_all.loc[xml_all['Exclude']=='Yes'].index).drop(columns='Exclude')\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for fname in np.unique(xml_all['fname']):\n",
        "    temp_df = xml_all[['fname', 'GALLERY', 'IOD']].loc[xml_all['fname']==fname].copy()\n",
        "    # the images are arranged in gallery and IOD ascneding order\n",
        "    temp_df.sort_values(['GALLERY', 'IOD'], ascending=[True, True], inplace=True)\n",
        "    temp_df.reset_index(inplace=True)\n",
        "    temp_df.index += 1\n",
        "    dfs.append(temp_df)\n",
        "dfs = pd.concat(dfs)\n",
        "\n",
        "dfs['image'] = dfs['fname'] + '_' + dfs.index.map(str)\n",
        "\n",
        "index_image_table = dfs[['GUID', 'image', 'GALLERY']].copy()\n",
        "index_image_table.set_index('GUID', inplace=True)\n",
        "\n",
        "# save\n",
        "#index_image_table.to_csv('index_to_image_lookup.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rdTteiVB3SYG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Extension: convolutional neural network\n",
        "Directly work with raw images"
      ]
    },
    {
      "metadata": {
        "id": "udjoEcwHNzDy",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title upload images data\n",
        "\n",
        "zip_ref = zipfile.ZipFile('images.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dSJEvUT63gVe",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Define function to standardize images\n",
        "\n",
        "def standardize_image(im, max_length):\n",
        "    h, w = im.shape\n",
        "    \n",
        "    \n",
        "    if h>max_length or w>max_length:\n",
        "        # downsize to fit\n",
        "        \n",
        "        # add padding to the shorter side\n",
        "        if h>w:\n",
        "            w_pad_before = int(np.floor((h - w)/2))\n",
        "            w_pad_after = int(h - w - w_pad_before)\n",
        "            im = np.pad(im, ((0, 0), (w_pad_before, w_pad_after)), mode='constant', constant_values=255)\n",
        "        elif h<w:\n",
        "            h_pad_before = int(np.floor((w - h)/2))\n",
        "            h_pad_after = int(w - h - h_pad_before)\n",
        "            im = np.pad(im, ((h_pad_before, h_pad_after), (0, 0)), mode='constant', constant_values=255)\n",
        "        \n",
        "        # scale down        \n",
        "        im = resize(image=im, output_shape=(max_length, max_length), mode='constant')\n",
        "        return 1 - im\n",
        "    else:\n",
        "        h_pad_before = int(np.floor((max_length - h)/2))\n",
        "        h_pad_after = int(max_length - h - h_pad_before)\n",
        "        w_pad_before = int(np.floor((max_length - w)/2))\n",
        "        w_pad_after = int(max_length - w - w_pad_before)\n",
        "        # add padding\n",
        "        im = np.pad(im, ((h_pad_before, h_pad_after), (w_pad_before, w_pad_after)), mode='constant', constant_values=255)\n",
        "        return 1 - (im / 255.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Z3FgFayN2O-",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title get images in subset and standardize\n",
        "\n",
        "max_input_size = 128\n",
        "images_all = np.zeros((temp.shape[0], max_input_size, max_input_size))\n",
        "#images_all = np.zeros((N, max_input_size, max_input_size))\n",
        "cwd = os.getcwd()\n",
        "on_cloud = cwd.startswith(r'/home/liyunlu3')\n",
        "for i in range(temp.shape[0]):\n",
        "    fname = temp.iloc[i]['fname']\n",
        "    file = index_image_table.loc[temp.index[i], 'image']\n",
        "    if on_cloud:\n",
        "        images_all[i] = standardize_image(imageio.imread('/home/liyunlu3/Documents/images/' + fname + '/' + file + '.png', pilmode='L'), max_input_size)\n",
        "    else: # on colab\n",
        "        images_all[i] = standardize_image(imageio.imread('/content/images/' + fname + '/' + file + '.png', pilmode='L'), max_input_size)\n",
        "images_all = np.expand_dims(images_all, axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ImsQtac6OARV",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title retrieve indices\n",
        "train_index = np.load('temporary files/train_index.npy')\n",
        "val_index = np.load('temporary files/val_index.npy')\n",
        "test_index = np.load('temporary files/test_index.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R9_Of-YpN9Ln",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title use the indices to prepare data sets\n",
        "\n",
        "\n",
        "train_data = DataSet(inputs=images_all[train_index],\n",
        "                     labels=df_tsne[['x-tsne', 'y-tsne']].values[train_index],\n",
        "                     aux_inputs=temp[['IOD', 'AREA']].values[train_index],\n",
        "                     aux_outputs=df_tsne['region'].values[train_index])\n",
        "val_data = DataSet(inputs=images_all[val_index],\n",
        "                   labels=df_tsne[['x-tsne', 'y-tsne']].values[val_index],\n",
        "                   aux_inputs=temp[['IOD', 'AREA']].values[val_index],\n",
        "                   aux_outputs=df_tsne['region'].values[val_index])\n",
        "test_data = DataSet(inputs=images_all[test_index],\n",
        "                    labels=df_tsne[['x-tsne', 'y-tsne']].values[test_index],\n",
        "                    aux_inputs=temp[['IOD', 'AREA']].values[test_index],\n",
        "                    aux_outputs=df_tsne['region'].values[test_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cpIMwqpXP1mP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cnn_layers = [8, 16, 32, 64, 128, 256, 512]\n",
        "fc_layers = [128,64]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cqws8WJWP0Fo",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Define CNN model with Keras\n",
        "\n",
        "x_ = Input(shape=(max_input_size, max_input_size, 1))\n",
        "\n",
        "x = x_\n",
        "for n in cnn_layers:\n",
        "    x = Conv2D(filters=n, kernel_size=3, strides=1, \n",
        "               padding='same', \n",
        "               activation='relu', name='conv'+str(n))(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), padding='valid')(x)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "aux_input = Input(shape=(2,), name='aux_input')\n",
        "x = concatenate([x, aux_input])\n",
        "\n",
        "i = 1\n",
        "for n in fc_layers:\n",
        "    x = Dense(units=n, activation='relu', name='fc'+str(i)+'_'+str(n))(x)\n",
        "    i += 1\n",
        "\n",
        "y = Dense(units=2, name='fc_final')(x)\n",
        "\n",
        "model = Model(inputs=[x_, aux_input], outputs=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z1YJcC2TQDf5",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Compile\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JZy8ab9ySiIf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_name_prefix = 'CNN_model_v0_'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qhg2nfLBRqLV",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title define metrics callback\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "class modelsaver(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self._min_mae = 6\n",
        "        if len(self.model.inputs)>1:\n",
        "            self._aux_in = True\n",
        "        else:\n",
        "            self._aux_in = False\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if l > self._min_mae:\n",
        "            file = 'Keras models/CNN/'+model_name_prefix+'_%.2f.h5' % logs['val_loss']\n",
        "            print('saving model at '+file)\n",
        "            self.model.save(file)\n",
        "            self._min_mae = l\n",
        "        return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xTWHE-9BRaMZ",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Configure callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1, min_lr=1e-6)\n",
        "saver = modelsaverï¼ˆï¼‰"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "86daT7f3QMlo",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title train\n",
        "model.fit([train_data._inputs, train_data._aux_inputs], train_data._labels, \n",
        "          epochs=300, batch_size=128, shuffle=True, \n",
        "          validation_data=([val_data._inputs, val_data._aux_inputs], val_data._labels), \n",
        "          sample_weight=df_tsne['region'].map(lambda x: 1 if x==0 else 1.5).iloc[train_index].values,\n",
        "          callbacks=[reduce_lr, saver])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PNgTWCk53g0_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Extension: Interactive fine-tuning"
      ]
    },
    {
      "metadata": {
        "id": "ly3ZIHss3rUk",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title define some utility functions\n",
        "def get_image(guid, max_size):\n",
        "    fname = xml_all.loc[guid, 'fname']\n",
        "    file = index_image_table.loc[guid, 'image']\n",
        "    im = standardize_image(imageio.imread('/home/liyunlu3/Documents/images/' + fname + '/' + file + '.png', \n",
        "                                          pilmode='L'), \n",
        "                           max_size)\n",
        "    return (im, file)\n",
        "\n",
        "def show_images(image1, fname1, image2, fname2):\n",
        "    plt.subplots(1,2,figsize=(10,20))\n",
        "    #plt.subplots(1,2)\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image1,cmap='gray')\n",
        "    plt.title(fname1)\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(image2,cmap='gray')\n",
        "    plt.title(fname2)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHPS5tBjixgW",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Hand tuning Main process\n",
        "\n",
        "cont = 'Y'\n",
        "force = 10\n",
        "\n",
        "while cont=='Y' or cont=='y':\n",
        "    # get the first image\n",
        "    # need to replace random sampling with either manual selection \n",
        "    # or local density based sampling\n",
        "    if to_sample:\n",
        "        # randomly choose a image with equal chance of choosing each gallery and each grade\n",
        "        gallery = np.random.randint(4)\n",
        "        grade = np.random.choice(['High','Low','Intermediate','Normal'],1)[0]\n",
        "\n",
        "        guid1 = np.random.choice(df_tsne.loc[(df_tsne['GALLERY']==gallery) & (df_tsne['Grade']==grade)].index.values, 1)[0]\n",
        "        im1, file1 = get_image(guid1, 128)\n",
        "    # otherwise continue with the same first image\n",
        "    \n",
        "    im1 = np.expand_dims(im, axis=-1)\n",
        "    current_output1 = model.predict(np.expand_dims(im1, axis=0), \n",
        "                                    batch_size=1)\n",
        "    \n",
        "    # get the second image\n",
        "    # randomly sample some images, retain only the nearest to image 1\n",
        "    N = 32\n",
        "    sample_index = np.random.choice(df_tsne.loc[(df_tsne['GALLERY']==gallery) & (df_tsne['Grade']==grade) & (df_tsne.index!=guid1)].index.values, N, replace=False)\n",
        "    \n",
        "    temp_im_list = []\n",
        "    temp_file_list = []\n",
        "    for guid in sample_index:\n",
        "        im, file = get_image(guid, 128)\n",
        "        temp_im_list.append(np.expand_dims(im, axis=-1))\n",
        "        temp_file_list.append(file)\n",
        "    outputs = model.predict(np.stack(temp_im_list, axis=0))\n",
        "    distances = np.linalg.norm(outputs - current_output1.reshape([1,2]), axis=1)\n",
        "    # get the id of the nearest image\n",
        "    guid2 = sample_index[np.argmin(distances)]\n",
        "    im2 = temp_im_list[np.argmin(distances)]\n",
        "    current_output2 = outputs[np.argmin(distances)]\n",
        "    distance = distances[np.argmin(distances)]\n",
        "    \n",
        "    image1, file1 = get_image(guid1, 282)\n",
        "    image2, file2 = get_image(guid2, 282)\n",
        "    \n",
        "    # plot images to compare by eye\n",
        "    clear_output()\n",
        "    print('Left image:', ['Tumour', 'Lymphocyte', 'Normal', 'Firoblast'][gallery], 'cell from', grade, 'grade sample')\n",
        "    show_images(image1, file1, image2, file2)\n",
        "    \n",
        "    print('Current distance:' + \"%.2f\" % distance)\n",
        "    \n",
        "    # receive label\n",
        "    signal = input('Are they similar? ')\n",
        "    if signal.find('stop')>-1:\n",
        "        cont='n'\n",
        "        if signal.startswith('y') or signal.startswith('Y'):\n",
        "            signal = 1\n",
        "            to_sample = True\n",
        "        else:\n",
        "            signal = -1\n",
        "            to_sample = False\n",
        "    elif signal=='Y' or signal=='y':\n",
        "        signal = 1\n",
        "        to_sample = True\n",
        "    else:\n",
        "        signal = -1\n",
        "        to_sample = False\n",
        "    #records.append((guid1, guid2, signal))\n",
        "    \n",
        "    # set target for the training\n",
        "    if signal==1:\n",
        "        target1 = (current_output1 + current_output2)/2.\n",
        "        target2 = target1\n",
        "    else:\n",
        "        target1 = current_output1 + (current_output1-current_output2) / (distance**2) * force\n",
        "        target2 = current_output2 + (current_output2-current_output1) / (distance**2) * force\n",
        "    \n",
        "    print('output1:', current_output1, 'new target:', target1)\n",
        "    print('output2:', current_output2, 'new target:', target2)\n",
        "    \n",
        "    # train with new targets\n",
        "    model.fit(np.stack([im1, im2]), \n",
        "              np.concatenate([target1, target2], axis=0))\n",
        "    \n",
        "    time.sleep(2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tXvQBHUBvyds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('Keras models/CNN_model_v1_tuned_.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}